{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:39.135184Z","iopub.status.busy":"2022-02-06T20:15:39.13476Z","iopub.status.idle":"2022-02-06T20:15:56.885586Z","shell.execute_reply":"2022-02-06T20:15:56.884398Z","shell.execute_reply.started":"2022-02-06T20:15:39.135044Z"},"trusted":true},"outputs":[],"source":["from typing import List, Optional, Dict, Any, Tuple\n","import os\n","from pathlib import Path\n","import copy\n","import time \n","from collections import defaultdict\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","import pickle\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import gc\n","import json\n","from tqdm import tqdm\n","try:\n","    import wandb\n","except Exception:\n","    !pip install --upgrade wandb\n","    import wandb\n","try:\n","    import timm\n","except Exception:\n","    !pip install --upgrade timm\n","    import timm\n","\n","pd.options.display.float_format = '{: ,.4f}'.format\n","pd.options.display.max_colwidth = 0\n","\n","try:\n","    from helpers import pandas_utils as pu, files as f, visualization as vis\n","    # raise\n","except Exception:\n","    !pip install -q -I git+http://github.com/PaulDanielML/common_utils.git\n","    from helpers import pandas_utils as pu, files as f, visualization as vis"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:56.888594Z","iopub.status.busy":"2022-02-06T20:15:56.888312Z","iopub.status.idle":"2022-02-06T20:15:56.947052Z","shell.execute_reply":"2022-02-06T20:15:56.945608Z","shell.execute_reply.started":"2022-02-06T20:15:56.888562Z"},"trusted":true},"outputs":[],"source":["CONFIG = {\n","    \"seed\": 319,\n","    \"epochs\": 5,\n","    \"img_size\": 448,\n","    \"args_hor_flip\": {\"p\": 0.5},\n","    \"args_ver_flip\": {\"p\": 0.5},\n","    \"args_rot\": {\"p\": 0.5, \"limit\": 30},\n","    \"model_name\": \"tf_efficientnet_b0\",\n","    \"num_classes\": 15587,\n","    \"train_batch_size\": 32,\n","    \"valid_batch_size\": 64,\n","    \"learning_rate\": 1e-4,\n","    \"scheduler\": \"CosineAnnealingLR\",\n","    \"min_lr\": 1e-6,\n","    \"T_max\": 500,\n","    \"weight_decay\": 1e-6,\n","    \"n_fold\": 5,\n","    \"n_accumulate\": 1,\n","    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","    # ArcFace Hyperparameters\n","    \"s\": 30.0,\n","    \"m\": 0.50,\n","    \"ls_eps\": 0.0,\n","    \"easy_margin\": False,\n","}\n","\n","\n","def make_transforms(config: Dict):\n","    param_mapping = {\n","        \"args_hor_flip\": A.HorizontalFlip,\n","        \"args_ver_flip\": A.VerticalFlip,\n","        \"args_rot\": A.Rotate,\n","    }\n","\n","    base_transforms = [\n","        A.Resize(config[\"img_size\"], config[\"img_size\"]),\n","        A.Normalize(\n","            mean=[0.485, 0.456, 0.406],\n","            std=[0.229, 0.224, 0.225],\n","        ),\n","        ToTensorV2(),\n","    ]\n","\n","    train_transforms = copy.deepcopy(base_transforms)\n","\n","    for arg_name, arg_class in param_mapping.items():\n","        if config[arg_name][\"p\"] > 0.0:\n","            train_transforms.insert(1, arg_class(**config[arg_name]))\n","\n","    return {\"train\": A.Compose(train_transforms), \"valid\": A.Compose(base_transforms)}\n","\n","transforms = make_transforms(CONFIG)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:56.950366Z","iopub.status.busy":"2022-02-06T20:15:56.949573Z","iopub.status.idle":"2022-02-06T20:15:56.967211Z","shell.execute_reply":"2022-02-06T20:15:56.966217Z","shell.execute_reply.started":"2022-02-06T20:15:56.950324Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed=42):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","set_seed(CONFIG['seed'])"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:56.971024Z","iopub.status.busy":"2022-02-06T20:15:56.970402Z","iopub.status.idle":"2022-02-06T20:15:58.778694Z","shell.execute_reply":"2022-02-06T20:15:58.777671Z","shell.execute_reply.started":"2022-02-06T20:15:56.970963Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n"]}],"source":["ON_KAGGLE_KERNEL = os.path.isdir(\"/kaggle/input\")\n","print(ON_KAGGLE_KERNEL)\n","if ON_KAGGLE_KERNEL:\n","    DATA_DIR = Path(\"/kaggle/input/happy-whale-and-dolphin\")\n","    try:\n","        from kaggle_secrets import UserSecretsClient\n","        user_secrets = UserSecretsClient()\n","        api_key = user_secrets.get_secret(\"wandb_api\")\n","        wandb.login(key=api_key)\n","        wandb_active = True\n","    except:\n","        wandb_active = False\n","else:\n","    from src import DATA_DIR, SUB_DIR"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:58.780613Z","iopub.status.busy":"2022-02-06T20:15:58.780221Z","iopub.status.idle":"2022-02-06T20:15:58.788719Z","shell.execute_reply":"2022-02-06T20:15:58.787658Z","shell.execute_reply.started":"2022-02-06T20:15:58.780572Z"},"trusted":true},"outputs":[],"source":["def encode_labels(df: pd.DataFrame) -> pd.DataFrame:\n","    enc = LabelEncoder()\n","    if \"individual_id\" not in df.columns:\n","        return df\n","    df = df.copy(deep=True)\n","    print(\"Encoding labels of df...\")\n","    df['individual_id'] = enc.fit_transform(df['individual_id'])\n","    # if not os.path.isfile(\"id_encoding.pickle\"):\n","    print(\"Saving new label encoder...\")\n","    with open(\"id_encoding.pickle\", \"wb\") as f:\n","        pickle.dump(enc, f)\n","\n","    return df"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:58.791378Z","iopub.status.busy":"2022-02-06T20:15:58.790626Z","iopub.status.idle":"2022-02-06T20:15:58.804955Z","shell.execute_reply":"2022-02-06T20:15:58.80395Z","shell.execute_reply.started":"2022-02-06T20:15:58.791331Z"},"trusted":true},"outputs":[],"source":["class WhaleDataset(Dataset):\n","    def __init__(\n","        self, df: pd.DataFrame, transforms: Optional[A.Compose] = None, labels: bool = True\n","    ):\n","        self.df = df.copy(deep=True)\n","        self.labels = labels\n","        self.transforms = transforms\n","        self.img_dir = DATA_DIR / \"train_images\" if labels else DATA_DIR / \"test_images\"\n","        self.df[\"img_path\"] = self.df[\"image\"].apply(lambda x: self.img_dir / x)\n","        if labels and (self.df[\"individual_id\"].dtype == \"object\"):\n","            self.df = encode_labels(self.df)\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        img = np.array(Image.open(row.img_path).convert(\"RGB\"))\n","\n","        if self.transforms:\n","            img = self.transforms(image=img)[\"image\"]\n","\n","        data = {\"image\": img}\n","        if not self.labels:\n","            # return data.update({\"img_name\": [row.image]})\n","            return data\n","        return data.update({\"label\": torch.tensor(row.individual_id, dtype=torch.long)})\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:58.808794Z","iopub.status.busy":"2022-02-06T20:15:58.807479Z","iopub.status.idle":"2022-02-06T20:15:58.816596Z","shell.execute_reply":"2022-02-06T20:15:58.81555Z","shell.execute_reply.started":"2022-02-06T20:15:58.808746Z"},"trusted":true},"outputs":[],"source":["def create_folds(df: pd.DataFrame) -> pd.DataFrame:\n","    df_local = df.copy(deep=True)\n","    print(\"Creating folds...\")\n","    skf = StratifiedKFold(5)\n","    for fold_number, (_, test_idx) in enumerate(skf.split(X=df_local, y=df_local.individual_id)):\n","        df_local.loc[test_idx, \"fold_number\"] = fold_number\n","    return df_local"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:58.819775Z","iopub.status.busy":"2022-02-06T20:15:58.818458Z","iopub.status.idle":"2022-02-06T20:15:58.832779Z","shell.execute_reply":"2022-02-06T20:15:58.831572Z","shell.execute_reply.started":"2022-02-06T20:15:58.819725Z"},"trusted":true},"outputs":[],"source":["def create_dataloaders(df: pd.DataFrame, fold: int = 0) -> Tuple[DataLoader, DataLoader]:\n","    df_train = df[df[\"fold_number\"] != fold].reset_index(drop=True)\n","    df_valid = df[df[\"fold_number\"] == fold].reset_index(drop=True)\n","\n","    train_dataset = WhaleDataset(df_train, transforms=transforms[\"train\"])\n","    valid_dataset = WhaleDataset(df_valid, transforms=transforms[\"valid\"])\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CONFIG[\"train_batch_size\"],\n","        num_workers=2,\n","        shuffle=True,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=CONFIG[\"valid_batch_size\"],\n","        num_workers=2,\n","        shuffle=False,\n","        pin_memory=True,\n","    )\n","\n","    return train_loader, valid_loader\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:15:58.837074Z","iopub.status.busy":"2022-02-06T20:15:58.836336Z","iopub.status.idle":"2022-02-06T20:16:05.029633Z","shell.execute_reply":"2022-02-06T20:16:05.028673Z","shell.execute_reply.started":"2022-02-06T20:15:58.837031Z"},"trusted":true},"outputs":[],"source":["model = timm.create_model(CONFIG[\"model_name\"], pretrained=True, num_classes=CONFIG[\"num_classes\"])\n","model.to(CONFIG['device']);\n","MODEL_TRAINED = False"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:16:05.033966Z","iopub.status.busy":"2022-02-06T20:16:05.033608Z","iopub.status.idle":"2022-02-06T20:16:05.03925Z","shell.execute_reply":"2022-02-06T20:16:05.037779Z","shell.execute_reply.started":"2022-02-06T20:16:05.033923Z"},"trusted":true},"outputs":[],"source":["def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:16:05.042008Z","iopub.status.busy":"2022-02-06T20:16:05.041492Z","iopub.status.idle":"2022-02-06T20:16:05.055755Z","shell.execute_reply":"2022-02-06T20:16:05.05454Z","shell.execute_reply.started":"2022-02-06T20:16:05.041826Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        images = data['image'].to(device, dtype=torch.float)\n","        labels = data['label'].to(device, dtype=torch.long)\n","        \n","        batch_size = images.size(0)\n","        \n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss = loss / CONFIG['n_accumulate']\n","            \n","        loss.backward()\n","    \n","        if (step + 1) % CONFIG['n_accumulate'] == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","                \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:16:05.058241Z","iopub.status.busy":"2022-02-06T20:16:05.057737Z","iopub.status.idle":"2022-02-06T20:16:05.071678Z","shell.execute_reply":"2022-02-06T20:16:05.070649Z","shell.execute_reply.started":"2022-02-06T20:16:05.058195Z"},"trusted":true},"outputs":[],"source":["@torch.inference_mode()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        images = data['image'].to(device, dtype=torch.float)\n","        labels = data['label'].to(device, dtype=torch.long)\n","        \n","        batch_size = images.size(0)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss)   \n","    \n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:16:12.431651Z","iopub.status.busy":"2022-02-06T20:16:12.428991Z","iopub.status.idle":"2022-02-06T20:16:12.45306Z","shell.execute_reply":"2022-02-06T20:16:12.451639Z","shell.execute_reply.started":"2022-02-06T20:16:12.431594Z"},"trusted":true},"outputs":[],"source":["def run_training(model, optimizer, scheduler, num_epochs):\n","    # To automatically log gradients\n","    wandb.watch(model, log_freq=100)\n","\n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","\n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = np.inf\n","    history = defaultdict(list)\n","\n","    for epoch in range(1, num_epochs + 1):\n","        gc.collect()\n","        train_epoch_loss = train_one_epoch(\n","            model,\n","            optimizer,\n","            scheduler,\n","            dataloader=train_loader,\n","            device=CONFIG[\"device\"],\n","            epoch=epoch,\n","        )\n","\n","        val_epoch_loss = valid_one_epoch(model, val_loader, device=CONFIG[\"device\"], epoch=epoch)\n","\n","        history[\"Train Loss\"].append(train_epoch_loss)\n","        history[\"Valid Loss\"].append(val_epoch_loss)\n","\n","        # Log the metrics\n","        wandb.log({\"Train Loss\": train_epoch_loss})\n","        wandb.log({\"Valid Loss\": val_epoch_loss})\n","\n","        # deep copy the model\n","        if val_epoch_loss <= best_epoch_loss:\n","            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n","            best_epoch_loss = val_epoch_loss\n","            run.summary[\"Best Loss\"] = best_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n","            torch.save(model.state_dict(), PATH)\n","            # Save a model file from the current directory\n","            print(f\"Model Saved.\")\n","\n","        print()\n","\n","    end = time.time()\n","    time_elapsed = end - start\n","    print(\n","        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n","            time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60\n","        )\n","    )\n","    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:16:12.463391Z","iopub.status.busy":"2022-02-06T20:16:12.459636Z","iopub.status.idle":"2022-02-06T20:16:12.475201Z","shell.execute_reply":"2022-02-06T20:16:12.474195Z","shell.execute_reply.started":"2022-02-06T20:16:12.463328Z"},"trusted":true},"outputs":[],"source":["def fetch_scheduler(optimizer):\n","    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n","                                                   eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n","                                                             eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == None:\n","        return None\n","        \n","    return scheduler"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-02-06T20:16:12.482642Z","iopub.status.busy":"2022-02-06T20:16:12.481245Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoding labels of df...\n","Saving new label encoder...\n","Creating folds...\n"]}],"source":["df: pd.DataFrame = pd.read_csv(DATA_DIR / \"train.csv\")\n","df = encode_labels(df)\n","df = create_folds(df)\n","train_loader, val_loader = create_dataloaders(df)\n","optimizer = optim.Adam(\n","    model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"]\n",")\n","scheduler = fetch_scheduler(optimizer)\n","\n","# run = wandb.init(\n","#     project=\"HappyWhale\",\n","#     config=CONFIG,\n","#     job_type=\"Train\",\n","#     tags=[\"Standard classifier\", \"efficientnet_b0\", \"448\"],\n","#     anonymous=\"must\",\n","# )\n","\n","# model, history = run_training(\n","#     model, optimizer, scheduler, num_epochs=CONFIG[\"epochs\"]\n","# )\n","# MODEL_TRAINED = True\n","# run.finish()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>species</th>\n","      <th>individual_id</th>\n","      <th>fold_number</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00021adfb725ed.jpg</td>\n","      <td>melon_headed_whale</td>\n","      <td>12348</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000562241d384d.jpg</td>\n","      <td>humpback_whale</td>\n","      <td>1636</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0007c33415ce37.jpg</td>\n","      <td>false_killer_whale</td>\n","      <td>5842</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0007d9bca26a99.jpg</td>\n","      <td>bottlenose_dolphin</td>\n","      <td>4551</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00087baf5cef7a.jpg</td>\n","      <td>humpback_whale</td>\n","      <td>8721</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>51028</th>\n","      <td>fff639a7a78b3f.jpg</td>\n","      <td>beluga</td>\n","      <td>5520</td>\n","      <td>4.0000</td>\n","    </tr>\n","    <tr>\n","      <th>51029</th>\n","      <td>fff8b32daff17e.jpg</td>\n","      <td>cuviers_beaked_whale</td>\n","      <td>1096</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>51030</th>\n","      <td>fff94675cc1aef.jpg</td>\n","      <td>blue_whale</td>\n","      <td>5116</td>\n","      <td>4.0000</td>\n","    </tr>\n","    <tr>\n","      <th>51031</th>\n","      <td>fffbc5dd642d8c.jpg</td>\n","      <td>beluga</td>\n","      <td>3909</td>\n","      <td>4.0000</td>\n","    </tr>\n","    <tr>\n","      <th>51032</th>\n","      <td>fffdcd42312777.jpg</td>\n","      <td>bottlenose_dolphin</td>\n","      <td>4715</td>\n","      <td>4.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>51033 rows × 4 columns</p>\n","</div>"],"text/plain":["                    image               species  individual_id  fold_number\n","0      00021adfb725ed.jpg  melon_headed_whale    12348          0.0000     \n","1      000562241d384d.jpg  humpback_whale        1636           1.0000     \n","2      0007c33415ce37.jpg  false_killer_whale    5842           0.0000     \n","3      0007d9bca26a99.jpg  bottlenose_dolphin    4551           0.0000     \n","4      00087baf5cef7a.jpg  humpback_whale        8721           0.0000     \n","...                   ...             ...         ...              ...     \n","51028  fff639a7a78b3f.jpg  beluga                5520           4.0000     \n","51029  fff8b32daff17e.jpg  cuviers_beaked_whale  1096           1.0000     \n","51030  fff94675cc1aef.jpg  blue_whale            5116           4.0000     \n","51031  fffbc5dd642d8c.jpg  beluga                3909           4.0000     \n","51032  fffdcd42312777.jpg  bottlenose_dolphin    4715           4.0000     \n","\n","[51033 rows x 4 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["if not MODEL_TRAINED:\n","    model = timm.create_model(CONFIG[\"model_name\"], pretrained=False, num_classes=CONFIG[\"num_classes\"])\n","    weights = torch.load(\"src/pytorch_classifier/weights/Loss7.1429_epoch5.bin\", map_location=torch.device(\"cpu\"))\n","    model.load_state_dict(weights)\n","    model.to(CONFIG[\"device\"])\n","    print(CONFIG[\"device\"])\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["df_test = pd.read_csv(\"data/sample_submission.csv\").drop(columns=\"predictions\")\n","EXAMPLE_IMAGE_PATH = str(DATA_DIR / \"test_images\" / df_test.iloc[10][\"image\"])\n","EXAMPLE_IMAGE = np.array(Image.open(EXAMPLE_IMAGE_PATH).convert(\"RGB\"))"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000110707af0ba.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0006287ec424cb.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000809ecb2ccad.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00098d1376dab2.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000b8d89c738bd.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                image\n","0  000110707af0ba.jpg\n","1  0006287ec424cb.jpg\n","2  000809ecb2ccad.jpg\n","3  00098d1376dab2.jpg\n","4  000b8d89c738bd.jpg"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head()"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["@torch.inference_mode()\n","def generate_predictions_pt(model: nn.Module) -> pd.DataFrame:\n","    df = pd.read_csv(\"data/sample_submission.csv\").drop(columns=\"predictions\")\n","    test_dataset = WhaleDataset(df, transforms[\"valid\"], labels=False)\n","    test_loader = DataLoader(dataset=test_dataset, num_workers=4, batch_size=32)\n","\n","    with open(\"id_encoding.pickle\", \"rb\") as f:\n","        enc = pickle.load(f)\n","\n","    data = []\n","    for batch in test_loader:\n","        imgs = batch[\"image\"].to(CONFIG[\"device\"])\n","        res = F.softmax(model(imgs))\n","\n","        top = res.cpu().topk(5)\n","        for idx, val in zip(top.indices.numpy().tolist(), top.values.numpy().tolist()):\n","            ids = enc.inverse_transform(idx).tolist()\n","            data.append(dict(zip(ids, val)))\n","\n","    return_vals = [{\"image\": df.iloc[i][\"image\"], \"top5\": json.dumps(d)} for i,d in enumerate(data)]\n","    return return_vals"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["def predict_new_ind(df: pd.DataFrame, softmax_thr: float):\n","    \n","    df_local = df.copy(deep=True)\n","\n","    def insert_new_ind(x, thr: float):\n","        data = json.loads(x)\n","        idvs = list(data.keys())\n","        ret_value = []\n","        for idx, (idv, score) in enumerate(data.items()):\n","            if score > thr:\n","                ret_value.append(idv)\n","            else:\n","                ret_value.append(\"new_individual\")\n","                ret_value += idvs[idx:len(idvs)-1]\n","                break\n","\n","        return \" \".join(ret_value)\n","\n","\n","    df_local[\"predictions\"] = df_local[\"top5\"].apply(lambda x: insert_new_ind(x, softmax_thr))\n","    return df_local.drop(columns=\"top5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test = pd.read_csv(DATA_DIR / \"intermediary\" / \"top_5.csv\")"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>top5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000110707af0ba.jpg</td>\n","      <td>{\"a2e4dcc14c5e\": 0.048154015094041824, \"fc0f7c162cc0\": 0.04443174600601196, \"348f0fca7d1b\": 0.03226540982723236, \"a8c9dfb8ac6f\": 0.03155897557735443, \"6f632b846891\": 0.029956575483083725}</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0006287ec424cb.jpg</td>\n","      <td>{\"04a9b1cad4d9\": 0.005956506356596947, \"7726d3269f17\": 0.005036056041717529, \"76b5aad6b790\": 0.00493953563272953, \"f1e6c5118903\": 0.004193905275315046, \"400d43387c48\": 0.0038329416420310736}</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000809ecb2ccad.jpg</td>\n","      <td>{\"322a18725969\": 0.05694717541337013, \"51081e431bca\": 0.03947136551141739, \"dba4e482f0ad\": 0.03235378861427307, \"124534ac8131\": 0.025195930153131485, \"ff26e042cd52\": 0.022467533126473427}</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00098d1376dab2.jpg</td>\n","      <td>{\"938b7e931166\": 0.024364719167351723, \"7362d7a01d00\": 0.01294273417443037, \"10e758eb503a\": 0.012121515348553658, \"82af241cd012\": 0.010554972104728222, \"1a20c92ffe68\": 0.010136610828340054}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000b8d89c738bd.jpg</td>\n","      <td>{\"bca71e9c5328\": 0.003027654020115733, \"4e0d7c4225de\": 0.0020641994196921587, \"da9cc7804e3a\": 0.0014235482085496187, \"34659a010623\": 0.001211889903061092, \"0674970efe22\": 0.0011706999503076077}</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>000e246888710c.jpg</td>\n","      <td>{\"68070283a5e9\": 0.0037413849495351315, \"fecc717ffcf8\": 0.003095830325037241, \"dcc1a00f7660\": 0.0027543315663933754, \"942976a11d81\": 0.002494653221219778, \"3b5263676547\": 0.0024914336390793324}</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>000eb6e73a31a5.jpg</td>\n","      <td>{\"be330f0c495c\": 0.045786287635564804, \"f195c38bcf17\": 0.03238629549741745, \"8bc942512479\": 0.03169039264321327, \"b54c1f8df53f\": 0.024487990885972977, \"cc0e0b020a90\": 0.023175328969955444}</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>000fe6ebfc9893.jpg</td>\n","      <td>{\"64082644c693\": 0.007232420612126589, \"fecc717ffcf8\": 0.006564832292497158, \"0f72263cd384\": 0.0056589096784591675, \"a636f358b4ae\": 0.005599102936685085, \"b602f1224dee\": 0.005490310024470091}</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0011f7a65044e4.jpg</td>\n","      <td>{\"abbeba14a290\": 0.004166478291153908, \"48503390869b\": 0.0029057348147034645, \"22df13dec9ef\": 0.002167642116546631, \"018aaba90625\": 0.001932745799422264, \"fb11f4414d62\": 0.0018401503330096602}</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0012ff300032e3.jpg</td>\n","      <td>{\"06ef73efe924\": 0.022979486733675003, \"8274ddd12a43\": 0.019005682319402695, \"9582cc692d85\": 0.018320536240935326, \"79c94459ece0\": 0.01826922781765461, \"da65f819073c\": 0.016991324722766876}</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                image  \\\n","0  000110707af0ba.jpg   \n","1  0006287ec424cb.jpg   \n","2  000809ecb2ccad.jpg   \n","3  00098d1376dab2.jpg   \n","4  000b8d89c738bd.jpg   \n","5  000e246888710c.jpg   \n","6  000eb6e73a31a5.jpg   \n","7  000fe6ebfc9893.jpg   \n","8  0011f7a65044e4.jpg   \n","9  0012ff300032e3.jpg   \n","\n","                                                                                                                                                                                                top5  \n","0  {\"a2e4dcc14c5e\": 0.048154015094041824, \"fc0f7c162cc0\": 0.04443174600601196, \"348f0fca7d1b\": 0.03226540982723236, \"a8c9dfb8ac6f\": 0.03155897557735443, \"6f632b846891\": 0.029956575483083725}        \n","1  {\"04a9b1cad4d9\": 0.005956506356596947, \"7726d3269f17\": 0.005036056041717529, \"76b5aad6b790\": 0.00493953563272953, \"f1e6c5118903\": 0.004193905275315046, \"400d43387c48\": 0.0038329416420310736}     \n","2  {\"322a18725969\": 0.05694717541337013, \"51081e431bca\": 0.03947136551141739, \"dba4e482f0ad\": 0.03235378861427307, \"124534ac8131\": 0.025195930153131485, \"ff26e042cd52\": 0.022467533126473427}        \n","3  {\"938b7e931166\": 0.024364719167351723, \"7362d7a01d00\": 0.01294273417443037, \"10e758eb503a\": 0.012121515348553658, \"82af241cd012\": 0.010554972104728222, \"1a20c92ffe68\": 0.010136610828340054}      \n","4  {\"bca71e9c5328\": 0.003027654020115733, \"4e0d7c4225de\": 0.0020641994196921587, \"da9cc7804e3a\": 0.0014235482085496187, \"34659a010623\": 0.001211889903061092, \"0674970efe22\": 0.0011706999503076077}  \n","5  {\"68070283a5e9\": 0.0037413849495351315, \"fecc717ffcf8\": 0.003095830325037241, \"dcc1a00f7660\": 0.0027543315663933754, \"942976a11d81\": 0.002494653221219778, \"3b5263676547\": 0.0024914336390793324}  \n","6  {\"be330f0c495c\": 0.045786287635564804, \"f195c38bcf17\": 0.03238629549741745, \"8bc942512479\": 0.03169039264321327, \"b54c1f8df53f\": 0.024487990885972977, \"cc0e0b020a90\": 0.023175328969955444}       \n","7  {\"64082644c693\": 0.007232420612126589, \"fecc717ffcf8\": 0.006564832292497158, \"0f72263cd384\": 0.0056589096784591675, \"a636f358b4ae\": 0.005599102936685085, \"b602f1224dee\": 0.005490310024470091}    \n","8  {\"abbeba14a290\": 0.004166478291153908, \"48503390869b\": 0.0029057348147034645, \"22df13dec9ef\": 0.002167642116546631, \"018aaba90625\": 0.001932745799422264, \"fb11f4414d62\": 0.0018401503330096602}   \n","9  {\"06ef73efe924\": 0.022979486733675003, \"8274ddd12a43\": 0.019005682319402695, \"9582cc692d85\": 0.018320536240935326, \"79c94459ece0\": 0.01826922781765461, \"da65f819073c\": 0.016991324722766876}      "]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["test.iloc[:10]"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["df_thr = predict_new_ind(test, 0.04).set_index(\"image\")"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>predictions</th>\n","    </tr>\n","    <tr>\n","      <th>image</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>000110707af0ba.jpg</th>\n","      <td>a2e4dcc14c5e fc0f7c162cc0 new_individual 348f0fca7d1b a8c9dfb8ac6f</td>\n","    </tr>\n","    <tr>\n","      <th>0006287ec424cb.jpg</th>\n","      <td>new_individual 04a9b1cad4d9 7726d3269f17 76b5aad6b790 f1e6c5118903</td>\n","    </tr>\n","    <tr>\n","      <th>000809ecb2ccad.jpg</th>\n","      <td>322a18725969 new_individual 51081e431bca dba4e482f0ad 124534ac8131</td>\n","    </tr>\n","    <tr>\n","      <th>00098d1376dab2.jpg</th>\n","      <td>new_individual 938b7e931166 7362d7a01d00 10e758eb503a 82af241cd012</td>\n","    </tr>\n","    <tr>\n","      <th>000b8d89c738bd.jpg</th>\n","      <td>new_individual bca71e9c5328 4e0d7c4225de da9cc7804e3a 34659a010623</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>fff6ff1989b5cd.jpg</th>\n","      <td>new_individual 3ee0c96472b9 be2aa86d0e5b aa169045adea b5e1ee74f22b</td>\n","    </tr>\n","    <tr>\n","      <th>fff8fd932b42cb.jpg</th>\n","      <td>new_individual b4e86d16be40 4e0d7c4225de 6738e57058f8 da9cc7804e3a</td>\n","    </tr>\n","    <tr>\n","      <th>fff96371332c16.jpg</th>\n","      <td>new_individual 8deb2171580e 7717e80dcc1a 4134fe49e6ca 322a18725969</td>\n","    </tr>\n","    <tr>\n","      <th>fffc1c4d3eabc7.jpg</th>\n","      <td>new_individual 180c0ab04dcd 4a67e64bd3b7 ea8160d46f8f 6642e34b23c8</td>\n","    </tr>\n","    <tr>\n","      <th>fffc50be10c175.jpg</th>\n","      <td>new_individual e33a507393ca 19c2bfaa0819 20916df9f20d abdf7726e5ec</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27956 rows × 1 columns</p>\n","</div>"],"text/plain":["                                                                           predictions\n","image                                                                                 \n","000110707af0ba.jpg  a2e4dcc14c5e fc0f7c162cc0 new_individual 348f0fca7d1b a8c9dfb8ac6f\n","0006287ec424cb.jpg  new_individual 04a9b1cad4d9 7726d3269f17 76b5aad6b790 f1e6c5118903\n","000809ecb2ccad.jpg  322a18725969 new_individual 51081e431bca dba4e482f0ad 124534ac8131\n","00098d1376dab2.jpg  new_individual 938b7e931166 7362d7a01d00 10e758eb503a 82af241cd012\n","000b8d89c738bd.jpg  new_individual bca71e9c5328 4e0d7c4225de da9cc7804e3a 34659a010623\n","...                                                                                ...\n","fff6ff1989b5cd.jpg  new_individual 3ee0c96472b9 be2aa86d0e5b aa169045adea b5e1ee74f22b\n","fff8fd932b42cb.jpg  new_individual b4e86d16be40 4e0d7c4225de 6738e57058f8 da9cc7804e3a\n","fff96371332c16.jpg  new_individual 8deb2171580e 7717e80dcc1a 4134fe49e6ca 322a18725969\n","fffc1c4d3eabc7.jpg  new_individual 180c0ab04dcd 4a67e64bd3b7 ea8160d46f8f 6642e34b23c8\n","fffc50be10c175.jpg  new_individual e33a507393ca 19c2bfaa0819 20916df9f20d abdf7726e5ec\n","\n","[27956 rows x 1 columns]"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["df_thr"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["df_thr.to_csv(SUB_DIR / \"pytorch_classifier_thr_0,04.csv\")"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000110707af0ba.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0006287ec424cb.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000809ecb2ccad.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00098d1376dab2.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000b8d89c738bd.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27951</th>\n","      <td>fff6ff1989b5cd.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>27952</th>\n","      <td>fff8fd932b42cb.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>27953</th>\n","      <td>fff96371332c16.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>27954</th>\n","      <td>fffc1c4d3eabc7.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>27955</th>\n","      <td>fffc50be10c175.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27956 rows × 1 columns</p>\n","</div>"],"text/plain":["                    image\n","0      000110707af0ba.jpg\n","1      0006287ec424cb.jpg\n","2      000809ecb2ccad.jpg\n","3      00098d1376dab2.jpg\n","4      000b8d89c738bd.jpg\n","...                   ...\n","27951  fff6ff1989b5cd.jpg\n","27952  fff8fd932b42cb.jpg\n","27953  fff96371332c16.jpg\n","27954  fffc1c4d3eabc7.jpg\n","27955  fffc50be10c175.jpg\n","\n","[27956 rows x 1 columns]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>top5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000110707af0ba.jpg</td>\n","      <td>{\"a2e4dcc14c5e\": 0.048154015094041824, \"fc0f7c162cc0\": 0.04443174600601196, \"348f0fca7d1b\": 0.03226540982723236, \"a8c9dfb8ac6f\": 0.03155897557735443, \"6f632b846891\": 0.029956575483083725}</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0006287ec424cb.jpg</td>\n","      <td>{\"04a9b1cad4d9\": 0.005956506356596947, \"7726d3269f17\": 0.005036056041717529, \"76b5aad6b790\": 0.00493953563272953, \"f1e6c5118903\": 0.004193905275315046, \"400d43387c48\": 0.0038329416420310736}</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000809ecb2ccad.jpg</td>\n","      <td>{\"322a18725969\": 0.05694717541337013, \"51081e431bca\": 0.03947136551141739, \"dba4e482f0ad\": 0.03235378861427307, \"124534ac8131\": 0.025195930153131485, \"ff26e042cd52\": 0.022467533126473427}</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00098d1376dab2.jpg</td>\n","      <td>{\"938b7e931166\": 0.024364719167351723, \"7362d7a01d00\": 0.01294273417443037, \"10e758eb503a\": 0.012121515348553658, \"82af241cd012\": 0.010554972104728222, \"1a20c92ffe68\": 0.010136610828340054}</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000b8d89c738bd.jpg</td>\n","      <td>{\"bca71e9c5328\": 0.003027654020115733, \"4e0d7c4225de\": 0.0020641994196921587, \"da9cc7804e3a\": 0.0014235482085496187, \"34659a010623\": 0.001211889903061092, \"0674970efe22\": 0.0011706999503076077}</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27951</th>\n","      <td>fff6ff1989b5cd.jpg</td>\n","      <td>{\"3ee0c96472b9\": 0.0030315646436065435, \"be2aa86d0e5b\": 0.00296629685908556, \"aa169045adea\": 0.002550827106460929, \"b5e1ee74f22b\": 0.0023754145950078964, \"84d91f8c1f99\": 0.00235398905351758}</td>\n","    </tr>\n","    <tr>\n","      <th>27952</th>\n","      <td>fff8fd932b42cb.jpg</td>\n","      <td>{\"b4e86d16be40\": 0.0008207089267671108, \"4e0d7c4225de\": 0.0005901279509998858, \"6738e57058f8\": 0.0005407998105511069, \"da9cc7804e3a\": 0.000521070440299809, \"1df65ac9eb57\": 0.00050784507766366}</td>\n","    </tr>\n","    <tr>\n","      <th>27953</th>\n","      <td>fff96371332c16.jpg</td>\n","      <td>{\"8deb2171580e\": 0.019156092777848244, \"7717e80dcc1a\": 0.01664147526025772, \"4134fe49e6ca\": 0.016524596139788628, \"322a18725969\": 0.013660775497555733, \"51081e431bca\": 0.012567386962473392}</td>\n","    </tr>\n","    <tr>\n","      <th>27954</th>\n","      <td>fffc1c4d3eabc7.jpg</td>\n","      <td>{\"180c0ab04dcd\": 0.025870470330119133, \"4a67e64bd3b7\": 0.021264269948005676, \"ea8160d46f8f\": 0.01371792983263731, \"6642e34b23c8\": 0.011253273114562035, \"be208651e012\": 0.010479174554347992}</td>\n","    </tr>\n","    <tr>\n","      <th>27955</th>\n","      <td>fffc50be10c175.jpg</td>\n","      <td>{\"e33a507393ca\": 0.0151632996276021, \"19c2bfaa0819\": 0.013925883919000626, \"20916df9f20d\": 0.013834045268595219, \"abdf7726e5ec\": 0.01373939961194992, \"528c6ef62a74\": 0.012691943906247616}</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27956 rows × 2 columns</p>\n","</div>"],"text/plain":["                    image  \\\n","0      000110707af0ba.jpg   \n","1      0006287ec424cb.jpg   \n","2      000809ecb2ccad.jpg   \n","3      00098d1376dab2.jpg   \n","4      000b8d89c738bd.jpg   \n","...                   ...   \n","27951  fff6ff1989b5cd.jpg   \n","27952  fff8fd932b42cb.jpg   \n","27953  fff96371332c16.jpg   \n","27954  fffc1c4d3eabc7.jpg   \n","27955  fffc50be10c175.jpg   \n","\n","                                                                                                                                                                                                    top5  \n","0      {\"a2e4dcc14c5e\": 0.048154015094041824, \"fc0f7c162cc0\": 0.04443174600601196, \"348f0fca7d1b\": 0.03226540982723236, \"a8c9dfb8ac6f\": 0.03155897557735443, \"6f632b846891\": 0.029956575483083725}        \n","1      {\"04a9b1cad4d9\": 0.005956506356596947, \"7726d3269f17\": 0.005036056041717529, \"76b5aad6b790\": 0.00493953563272953, \"f1e6c5118903\": 0.004193905275315046, \"400d43387c48\": 0.0038329416420310736}     \n","2      {\"322a18725969\": 0.05694717541337013, \"51081e431bca\": 0.03947136551141739, \"dba4e482f0ad\": 0.03235378861427307, \"124534ac8131\": 0.025195930153131485, \"ff26e042cd52\": 0.022467533126473427}        \n","3      {\"938b7e931166\": 0.024364719167351723, \"7362d7a01d00\": 0.01294273417443037, \"10e758eb503a\": 0.012121515348553658, \"82af241cd012\": 0.010554972104728222, \"1a20c92ffe68\": 0.010136610828340054}      \n","4      {\"bca71e9c5328\": 0.003027654020115733, \"4e0d7c4225de\": 0.0020641994196921587, \"da9cc7804e3a\": 0.0014235482085496187, \"34659a010623\": 0.001211889903061092, \"0674970efe22\": 0.0011706999503076077}  \n","...                                                                                                                                                                                                  ...  \n","27951  {\"3ee0c96472b9\": 0.0030315646436065435, \"be2aa86d0e5b\": 0.00296629685908556, \"aa169045adea\": 0.002550827106460929, \"b5e1ee74f22b\": 0.0023754145950078964, \"84d91f8c1f99\": 0.00235398905351758}     \n","27952  {\"b4e86d16be40\": 0.0008207089267671108, \"4e0d7c4225de\": 0.0005901279509998858, \"6738e57058f8\": 0.0005407998105511069, \"da9cc7804e3a\": 0.000521070440299809, \"1df65ac9eb57\": 0.00050784507766366}   \n","27953  {\"8deb2171580e\": 0.019156092777848244, \"7717e80dcc1a\": 0.01664147526025772, \"4134fe49e6ca\": 0.016524596139788628, \"322a18725969\": 0.013660775497555733, \"51081e431bca\": 0.012567386962473392}      \n","27954  {\"180c0ab04dcd\": 0.025870470330119133, \"4a67e64bd3b7\": 0.021264269948005676, \"ea8160d46f8f\": 0.01371792983263731, \"6642e34b23c8\": 0.011253273114562035, \"be208651e012\": 0.010479174554347992}      \n","27955  {\"e33a507393ca\": 0.0151632996276021, \"19c2bfaa0819\": 0.013925883919000626, \"20916df9f20d\": 0.013834045268595219, \"abdf7726e5ec\": 0.01373939961194992, \"528c6ef62a74\": 0.012691943906247616}        \n","\n","[27956 rows x 2 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["test"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["test = generate_predictions_pt(model)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000110707af0ba.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0006287ec424cb.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000809ecb2ccad.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00098d1376dab2.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>000b8d89c738bd.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                image\n","0  000110707af0ba.jpg\n","1  0006287ec424cb.jpg\n","2  000809ecb2ccad.jpg\n","3  00098d1376dab2.jpg\n","4  000b8d89c738bd.jpg"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head()"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["pd.DataFrame(test).set_index(\"image\").to_csv(DATA_DIR / \"intermediary\" / \"top_5.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":4}
