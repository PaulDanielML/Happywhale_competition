{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/paul/projects/Happywhale_competition/data/cropped\n","timm found and imported (version 0.4.12).\n","wandb found and imported (version 0.12.10).\n"]}],"source":["import os\n","ON_KAGGLE_KERNEL = os.path.isdir(\"/kaggle/input\")\n","start_dir = os.getcwd()\n","\n","if ON_KAGGLE_KERNEL:\n","    os.chdir(\"/kaggle/input/utilities/\")\n","else:\n","    os.chdir(f\"{os.environ.get('PYTHONPATH')}/src/utils\")\n","\n","from common import load_structure, save_structure, load_train_file, INPUT_DATA_DIR, OUTPUT_DATA_DIR, SUB_DIR, set_seed, WANDB_KEY, WEIGHTS_DIR, load_test_file\n","from data_proc import create_idvs_with_one_img_in_train_split, create_train_val_loaders, split_into_train_val, encode_labels\n","from data_structures import WhaleDataset, TorchConfig, InferenceKNNModel\n","os.chdir(start_dir)\n","\n","print(INPUT_DATA_DIR)\n","\n","import importlib\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import math\n","from tqdm import tqdm\n","import gc\n","import time \n","import copy\n","\n","def _import_or_install(name: str):\n","    try:\n","        globals()[name] = importlib.import_module(name)\n","        # importlib.import_module(name)\n","        print(f\"{name} found and imported (version {globals()[name].__version__}).\")\n","    except ModuleNotFoundError:\n","        !pip install -q --upgrade $name\n","        # importlib.import_module(name)\n","        globals()[name] = importlib.import_module(name)\n","        print(f\"{name} Installed and imported (version {globals()[name].__version__}).\")\n","\n","\n","_import_or_install(\"timm\")\n","_import_or_install(\"wandb\")\n","\n","if ON_KAGGLE_KERNEL:\n","    try:\n","        wandb.login(key=WANDB_KEY)\n","    except Exception as e:\n","        print(f\"WandB login failed:\\n{e}\")\n","else:\n","    %reload_ext autoreload\n","    %autoreload 2\n","    from IPython.core.interactiveshell import InteractiveShell\n","    InteractiveShell.ast_node_interactivity = 'all'\n","\n","\n","\n","def _load_prev_weights():\n","    weight_file = sorted(os.listdir(WEIGHTS_DIR))[0]\n","    print(f\"Using weight file {weight_file}.\")\n","    return torch.load(str(WEIGHTS_DIR / weight_file), map_location=\"cpu\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["{'seed': 319,\n"," 'epochs': 10,\n"," 'img_size': 448,\n"," 'augm_args': {'hor_flip': {'p': 0.5},\n","  'ver_flip': {'p': 0.5},\n","  'rot': {'p': 0.5, 'limit': 30}},\n"," 'model_name': 'tf_efficientnet_b0',\n"," 'num_classes': 15587,\n"," 'train_batch_size': 32,\n"," 'valid_batch_size': 64,\n"," 'optim': torch.optim.adam.Adam,\n"," 'optim_args': {'lr': 0.0001, 'weight_decay': 1e-06},\n"," 'scheduler': torch.optim.lr_scheduler.CosineAnnealingLR,\n"," 'scheduler_args': {'T_max': 500, 'eta_min': 1e-06},\n"," 'n_fold': 5,\n"," 'init_optim_': None,\n"," 'init_sched_': None,\n"," 's': 30.0,\n"," 'm': 0.5,\n"," 'ls_eps': 0.0,\n"," 'easy_margin': False}"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["conf = TorchConfig.default()\n","conf.dict()\n","set_seed(conf.seed)\n","\n","conf.epochs = 20\n","\n","if not ON_KAGGLE_KERNEL:\n","    conf.train_batch_size = 1"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class GeM(nn.Module):\n","    def __init__(self, p=3, eps=1e-6):\n","        super(GeM, self).__init__()\n","        self.p = nn.Parameter(torch.ones(1)*p)\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        return self.gem(x, p=self.p, eps=self.eps)\n","        \n","    def gem(self, x, p=3, eps=1e-6):\n","        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n","        \n","    def __repr__(self):\n","        return self.__class__.__name__ + \\\n","                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n","                ', ' + 'eps=' + str(self.eps) + ')'"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class ArcMarginProduct(nn.Module):\n","    r\"\"\"Implement of large margin arc distance: :\n","    Args:\n","        in_features: size of each input sample\n","        out_features: size of each output sample\n","        s: norm of input feature\n","        m: margin\n","        cos(theta + m)\n","    \"\"\"\n","\n","    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n","        super(ArcMarginProduct, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.s = s\n","        self.m = m\n","        self.ls_eps = ls_eps  # label smoothing\n","        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n","        nn.init.xavier_uniform_(self.weight)\n","\n","        self.easy_margin = easy_margin\n","        self.cos_m = math.cos(m)\n","        self.sin_m = math.sin(m)\n","        self.th = math.cos(math.pi - m)\n","        self.mm = math.sin(math.pi - m) * m\n","\n","    def forward(self, input, label):\n","        # --------------------------- cos(theta) & phi(theta) ---------------------\n","        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n","        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n","        phi = cosine * self.cos_m - sine * self.sin_m\n","        if self.easy_margin:\n","            phi = torch.where(cosine > 0, phi, cosine)\n","        else:\n","            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n","        # --------------------------- convert label to one-hot ---------------------\n","        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n","        one_hot = torch.zeros(cosine.size(), device=device)\n","        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n","        if self.ls_eps > 0:\n","            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n","        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n","        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n","        output *= self.s\n","\n","        return output\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class HappyWhaleModel(nn.Module):\n","    def __init__(self, model_name, pretrained=True):\n","        super(HappyWhaleModel, self).__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained)\n","        in_features = self.model.classifier.in_features\n","        self.model.classifier = nn.Identity()\n","        self.model.global_pool = nn.Identity()\n","        self.pooling = GeM()\n","        self.fc = ArcMarginProduct(\n","            in_features,\n","            conf.num_classes,\n","            s=conf.s,\n","            m=conf.m,\n","            easy_margin=conf.easy_margin,\n","            ls_eps=conf.ls_eps,\n","        )\n","\n","    def forward(self, images, labels=None):\n","        features = self.model(images)\n","        # pooled_features = self.pooling(features)\n","        pooled_features = self.pooling(features).flatten(1)\n","        if labels is not None:\n","            output = self.fc(pooled_features, labels)\n","        else:\n","            output = self.fc(pooled_features)\n","        return output\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/paul/projects/Happywhale_competition/data/id_encoding.pickle saved.\n","/home/paul/projects/Happywhale_competition/data/splits/idvs_with_one_img_in_train.pickle saved.\n"]},{"data":{"text/plain":["(40589, 10444)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["Using weight file Loss12.9268_epoch5.bin.\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["HappyWhaleModel(\n","  (model): EfficientNet(\n","    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act1): SiLU(inplace=True)\n","    (blocks): Sequential(\n","      (0): Sequential(\n","        (0): DepthwiseSeparableConv(\n","          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): Identity()\n","        )\n","      )\n","      (1): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n","          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n","          (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n","          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","          (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n","          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): InvertedResidual(\n","          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act2): SiLU(inplace=True)\n","    (global_pool): Identity()\n","    (classifier): Identity()\n","  )\n","  (pooling): GeM(p=2.9141, eps=1e-06)\n","  (fc): ArcMarginProduct()\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df = create_idvs_with_one_img_in_train_split()\n","df_train, df_val = split_into_train_val(df)\n","len(df_train), len(df_val)\n","transforms = conf.make_transforms()\n","train_set = WhaleDataset(df_train, transforms[\"train\"])\n","val_set = WhaleDataset(df_val, transforms[\"valid\"])\n","train_loader, val_loader = create_train_val_loaders(\n","    train_set, val_set, conf.train_batch_size, conf.valid_batch_size\n",")\n","model = HappyWhaleModel(conf.model_name)\n","model.load_state_dict(_load_prev_weights())\n","model.to(device);\n","\n","optim = conf.get_optim(model)\n","scheduler = conf.get_scheduler()\n","def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def train_one_epoch(model, optimizer, dataloader, device, epoch):\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        images = data['image'].to(device, dtype=torch.float)\n","        labels = data['label'].to(device, dtype=torch.long)\n","        \n","        batch_size = images.size(0)\n","        \n","        outputs = model(images, labels)\n","        loss = criterion(outputs, labels)\n","        # loss = loss / conf['n_accumulate']\n","            \n","        loss.backward()\n","    \n","        # if (step + 1) % CONFIG['n_accumulate'] == 0:\n","        optimizer.step()\n","\n","        optimizer.zero_grad()\n","                \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["@torch.inference_mode()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        images = data['image'].to(device, dtype=torch.float)\n","        labels = data['label'].to(device, dtype=torch.long)\n","        \n","        batch_size = images.size(0)\n","\n","        outputs = model(images, labels)\n","        loss = criterion(outputs, labels)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss)   \n","    \n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def run_training(model, optimizer, scheduler, num_epochs):\n","    if ON_KAGGLE_KERNEL:\n","        wandb.watch(model, log_freq=100)\n","\n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","\n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = np.inf\n","\n","    for epoch in range(1, num_epochs + 1):\n","        gc.collect()\n","        train_epoch_loss = train_one_epoch(\n","            model,\n","            optimizer,\n","            dataloader=train_loader,\n","            device=device,\n","            epoch=epoch,\n","        )\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        val_epoch_loss = valid_one_epoch(model, val_loader, device=device, epoch=epoch)\n","\n","        # Log the metrics\n","        wandb.log({\"Train Loss\": train_epoch_loss})\n","        wandb.log({\"Valid Loss\": val_epoch_loss})\n","\n","        # deep copy the model\n","        if val_epoch_loss <= best_epoch_loss:\n","            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n","            best_epoch_loss = val_epoch_loss\n","            run.summary[\"Best Loss\"] = best_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n","            torch.save(model.state_dict(), PATH)\n","            # Save a model file from the current directory\n","            print(f\"Model Saved.\")\n","\n","        print()\n","\n","    end = time.time()\n","    time_elapsed = end - start\n","    print(\n","        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n","            time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60\n","        )\n","    )\n","    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["if ON_KAGGLE_KERNEL:\n","    run = wandb.init(\n","    project=\"HappyWhale\",\n","    config=conf.dict(),\n","    job_type=\"Train\",\n","    tags=[\"Standard classifier\", \"efficientnet_b0\", \"448\"],\n","    anonymous=\"must\",\n",")\n","\n","    model = run_training(model, optim, scheduler, num_epochs=conf.epochs)\n","\n","if ON_KAGGLE_KERNEL:\n","    run.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["[('model.blocks.6.0.se.gate', Sigmoid()),\n"," ('model.blocks.6.0.conv_pwl',\n","  Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n"," ('model.blocks.6.0.bn3',\n","  BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)),\n"," ('model.conv_head',\n","  Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n"," ('model.bn2',\n","  BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)),\n"," ('model.act2', SiLU(inplace=True)),\n"," ('model.global_pool', Identity()),\n"," ('model.classifier', Identity()),\n"," ('pooling', GeM(p=2.9141, eps=1e-06)),\n"," ('fc', ArcMarginProduct())]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["[torch.Size([1280, 320, 1, 1]),\n"," torch.Size([1280]),\n"," torch.Size([1280]),\n"," torch.Size([1]),\n"," torch.Size([15587, 1280])]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["torch.Size([1, 3, 448, 448])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["Using weight file Loss12.9268_epoch5.bin.\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["HappyWhaleModel(\n","  (model): EfficientNet(\n","    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act1): SiLU(inplace=True)\n","    (blocks): Sequential(\n","      (0): Sequential(\n","        (0): DepthwiseSeparableConv(\n","          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","          (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): Identity()\n","        )\n","      )\n","      (1): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n","          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","          (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (2): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n","          (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (3): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n","          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (4): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","          (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n","          (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): InvertedResidual(\n","          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): InvertedResidual(\n","          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): InvertedResidual(\n","          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): Sequential(\n","        (0): InvertedResidual(\n","          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): SiLU(inplace=True)\n","          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","          (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          (act2): SiLU(inplace=True)\n","          (se): SqueezeExcite(\n","            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","            (act1): SiLU(inplace=True)\n","            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","            (gate): Sigmoid()\n","          )\n","          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn2): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    (act2): SiLU(inplace=True)\n","    (global_pool): Identity()\n","    (classifier): Identity()\n","  )\n","  (pooling): GeM(p=2.9141, eps=1e-06)\n","  (fc): Identity()\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["4007549"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["[m for m in model.named_modules()][-10:]\n","[par.shape for par in model.parameters()][-5:]\n","test_dataset = WhaleDataset(load_test_file(), transforms[\"valid\"], labels=False)\n","test_input = test_dataset[10][\"image\"].unsqueeze(0)\n","test_input.shape\n","model = model.to(\"cpu\")\n","model.load_state_dict(_load_prev_weights())\n","\n","model.fc = nn.Identity()\n","model.eval()\n","sum(p.numel() for p in model.parameters())\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# InferenceKNNModel.list_all()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Embeddings loaded from /home/paul/projects/Happywhale_competition/data/embeddings/2_ArcFace_first_try_uncropped\n","Found previous train embeddings for 2_ArcFace_first_try_uncropped.\n","Found previous test embeddings for 2_ArcFace_first_try_uncropped.\n","train embeddings: Already complete.\n","test embeddings: Already complete.\n","[t-SNE] Computing 91 nearest neighbors...\n","[t-SNE] Indexed 78989 samples in 0.003s...\n","[t-SNE] Computed neighbors for 78989 samples in 157.514s...\n","[t-SNE] Computed conditional probabilities for sample 1000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 2000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 3000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 4000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 5000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 6000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 7000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 8000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 9000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 10000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 11000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 12000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 13000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 14000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 15000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 16000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 17000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 18000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 19000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 20000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 21000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 22000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 23000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 24000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 25000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 26000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 27000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 28000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 29000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 30000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 31000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 32000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 33000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 34000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 35000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 36000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 37000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 38000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 39000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 40000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 41000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 42000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 43000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 44000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 45000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 46000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 47000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 48000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 49000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 50000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 51000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 52000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 53000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 54000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 55000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 56000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 57000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 58000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 59000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 60000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 61000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 62000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 63000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 64000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 65000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 66000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 67000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 68000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 69000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 70000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 71000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 72000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 73000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 74000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 75000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 76000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 77000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 78000 / 78989\n","[t-SNE] Computed conditional probabilities for sample 78989 / 78989\n","[t-SNE] Mean sigma: 1.009586\n","[t-SNE] KL divergence after 250 iterations with early exaggeration: 88.286179\n","[t-SNE] KL divergence after 1000 iterations: 2.479979\n","/home/paul/projects/Happywhale_competition/data/embeddings/2_ArcFace_first_try_uncropped.pickle saved.\n","Possible species values are:\n","['melon_headed_whale', 'humpback_whale', 'false_killer_whale', 'bottlenose_dolphin', 'beluga', 'minke_whale', 'fin_whale', 'blue_whale', 'gray_whale', 'southern_right_whale', 'common_dolphin', 'killer_whale', 'short_finned_pilot_whale', 'dusky_dolphin', 'long_finned_pilot_whale', 'sei_whale', 'spinner_dolphin', 'cuviers_beaked_whale', 'spotted_dolphin', 'brydes_whale', 'commersons_dolphin', 'white_sided_dolphin', 'rough_toothed_dolphin', 'pantropic_spotted_dolphin', 'pygmy_killer_whale', 'frasiers_dolphin', 'Test']\n","/home/paul/projects/Happywhale_competition/data/embeddings/2_ArcFace_first_try_uncropped.pickle saved.\n","CV to find threshold finished. Best threshold: 0.1, best score: 0.25024189818794584.\n","/home/paul/projects/Happywhale_competition/data/embeddings/2_ArcFace_first_try_uncropped.pickle saved.\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 2.29M/2.29M [00:10<00:00, 233kB/s] \n"]},{"name":"stdout","output_type":"stream","text":["Successfully submitted to Happywhale - Whale and Dolphin IdentificationfileName                               date                 description                    status    publicScore  privateScore  \n","-------------------------------------  -------------------  -----------------------------  --------  -----------  ------------  \n","sub_2_ArcFace_first_try_uncropped.csv  2022-02-27 12:15:46  2_ArcFace_first_try_uncropped  complete  0.162        None          \n","sub_ArcFace_first_try_uncropped.csv    2022-02-26 20:16:40  ArcFace_first_try_uncropped    complete  0.175        None          \n","baseline_2.csv                         2022-02-24 12:13:38  python_subm_test               complete  0.113        None          \n","pytorch_classifier_thr_004.csv         2022-02-07 15:04:33  csv                            complete  0.145        None          \n","pytorch_classifier_thr_0.03.csv        2022-02-07 15:03:40  03                             complete  0.145        None          \n","pytorch_classifier_3.csv               2022-02-07 15:02:39  csv                            complete  0.141        None          \n","pytorch_classifier_2.csv               2022-02-07 15:01:55  csv                            complete  0.061        None          \n","pytorch_classifier_1.csv               2022-02-07 15:00:49  csv                            complete  0.128        None          \n","baseline_2.csv                         2022-02-06 18:03:59  csv                            complete  0.113        None          \n","baseline_1.csv                         2022-02-05 11:54:54  csv                            complete  0.112        None          \n","2.test                                 2022-02-03 20:50:43  test                           error     None         None          \n","2.test                                 2022-02-03 20:46:36  test                           error     None         None          \n"]}],"source":["im = InferenceKNNModel(model, name=\"2_ArcFace_first_try_uncropped\")\n","im.end_to_end()"]}],"metadata":{"interpreter":{"hash":"3d5c075392d29132b662e04dfe399f321127320a5d404537ff18030005fe1d27"},"kernelspec":{"display_name":"Python 3.9.5 ('env': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
